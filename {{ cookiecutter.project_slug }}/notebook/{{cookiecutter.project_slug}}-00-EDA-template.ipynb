{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This is the exploratory data analysis (EDA) template. It provides some initial lines of code that will help you start to explore your data. In the process of building out a Datascience workflow, we will all be doing EDA and this is a good place codify that and allow others to repeat your EDA.\n",
    "\n",
    "The steps here are a template/tutorial, and you should feel free to overwrite/make these your own. If you find yourself changing/deleting/adding things repeatedly for each project that you build, that may be a good candidate for something that needs to be changed with the template itself. Please post suggestions in #datascience_team or DM @Jake Smart in slack.\n",
    "\n",
    "The flow of this template is:\n",
    "1. Configure environment\n",
    "2. Get data \n",
    "3. Preprocess data\n",
    "4. Profile the data\n",
    "5. Do custom EDA (Your code goes in this section)\n",
    "6. Generate Great Expectations (Required for all dagster flows)\n",
    "7. Persist them \n",
    "\n",
    "*When committing this notebook to the repo, it is generally preferable to clear all the output for cleaner changelogs. We may look into packages that handle commits with outputs cleanly.*\n",
    "\n",
    "***Run this template at least once prior to running a dagster to generate your expectations***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data ingestion and profiling modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from drizly_dagster_utils.integrations import snowflake\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pandas_profiling import ProfileReport\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query\n",
    "Note: If you are building a project that isn't going in Dagster and you want to change the configuration file, you'll need to adapt the access to the cfg Box object (the dot notation) to match the format of your configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The query gets read from config.py defined in the ds_util directory.\n",
    "# The configuration: cfg gets it's definition from environment variables \n",
    "# (e.g. if DAGSTER_ENVIRONMENT = prod then prod_config.yaml gets read)\n",
    "import os\n",
    "os.chdir('..')\n",
    "from pipelines.{{cookiecutter.project_slug}}.environments.dev_run_config import dev_run_config\n",
    "config = dev_run_config\n",
    "query = config[\"solids\"][\"get_{{cookiecutter.project_slug}}_df\"][\"inputs\"][\"query\"][\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For visibility into what you are loading\n",
    "\n",
    "print(f'Config environment variable used:{config}')\n",
    "print(f'Config absolute path (In docker container if running there):{os.getcwd()}')\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This uses ~.aws/credentials to access snowflake (See cookiecutter setup if you are having issues here)\n",
    "df = snowflake.SnowflakeConn.from_secret('snowflake/analytics_api').get_pandas_dataframe(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_timestamp_columns = ['date', 'created_at','updated_at','dt','timestamp','event_time']\n",
    "for column in df.columns:\n",
    "    if str(column).lower() in common_timestamp_columns:\n",
    "        print(f\"Updating {column} from object to datetime\")\n",
    "        df[column] = pd.to_datetime(df[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic column information and counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data profiling\n",
    "This can be written to disk using the to_file(filename) command or it can be displayed directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = ProfileReport(df, explorative = True)\n",
    "pr.to_file(\"00-EDA-template-profile.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pairwise analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the default theme for seaborn\n",
    "sns.set_theme()\n",
    "sns.pairplot(df[df.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Great Expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import great expectations packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as ge\n",
    "import great_expectations.jupyter_ux\n",
    "from great_expectations.data_context.types.resource_identifiers import ValidationResultIdentifier\n",
    "from great_expectations.dataset import (\n",
    "    PandasDataset,\n",
    "    MetaPandasDataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert your dataframe into a GE dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge_df = ge.from_pandas(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the template \n",
    "The directory here is built by the command `great_expectations init,` but the cookiecutter template should have this already populated for you. This is where your expectations will get saved, and this is where Dagster will pull them from to run validation against flows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the great expectations context from \n",
    "print(config)\n",
    "great_expecations_directory = config[\"resources\"][\"ge_data_context\"][\"config\"][\"ge_root_dir\"]\n",
    "context = ge.data_context.DataContext(context_root_dir=great_expecations_directory)\n",
    "print(f\"Loaded great expectations from {great_expecations_directory}\")\n",
    "# Name your suite whatever you want. This is the project template name\n",
    "expectation_suite_name = \"{{cookiecutter.project_slug}}.basic.warning\"\n",
    "\n",
    "# The arg overwrite_existing=True can be added if you want to overwrite stuff that is already there\n",
    "es = context.create_expectation_suite(expectation_suite_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure the data you will use for creating expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasource can be changed to be non-pandas (a local file, a file in s3, another database)\n",
    "# and the dataset will need to change accordingly\n",
    "batch_kwargs = {\n",
    "    'dataset': df,\n",
    "    'datasource': \"pandas\"\n",
    "}\n",
    "\n",
    "batch = context.get_batch(batch_kwargs, expectation_suite_name)\n",
    "#Test that the batch has data and see what it is\n",
    "batch.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start to explore expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write some expectations\n",
    "Below are a few sample explicit expectations to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.expect_column_values_to_not_be_null(\"store_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.expect_column_values_to_not_be_null(column=\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.expect_column_values_to_be_between(\"store_order_total\", min_value = 0.0, max_value = 10000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.expect_column_values_to_not_be_in_set(column=\"store_state\", value_set=[\"fakeville\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.expect_compound_columns_to_be_unique([\"store_id\", \"user_id\", \"is_gift\", \"eta\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = batch.get_expectation_suite()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist the expectations so Dagster can use them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.save_expectation_suite(suite, expectation_suite_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test expectations by running validate against a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate\n",
    "results = context.run_validation_operator(\"action_list_operator\", assets_to_validate=[batch])\n",
    "\n",
    "# build the documentation for the result\n",
    "validation_result_identifier = results.list_validation_result_identifiers()[0]\n",
    "context.build_data_docs()\n",
    "data_docs_urls = context.get_docs_sites_urls(\n",
    "            resource_identifier=validation_result_identifier,\n",
    "            only_if_exists=False,\n",
    "        )\n",
    "urls_to_open = [site[\"site_url\"] for site in data_docs_urls]\n",
    "url = urls_to_open[0].replace('file:///work/', 'http://localhost:8888/view/')\n",
    "\n",
    "# You'll need to paste this in your browser if you are running this in the container\n",
    "# if needed you can add `+f'?token={access_token}' to the end of the above line where the access token \n",
    "# is generated by your notebook server \n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filepath =  \"pipelines/{{cookiecutter.project_slug}}/data/test.csv\"\n",
    "df.sample(n=5).to_csv(test_filepath, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
